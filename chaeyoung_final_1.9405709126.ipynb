{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"submit_0826_2_1.9405709126.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNssNqQOwnf7DwwnfwYtEsI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## import modeule"],"metadata":{"id":"pA-oDjsVOeIb"}},{"cell_type":"code","source":["!pip install bayesian-optimization"],"metadata":{"id":"PBfvHaM5OZir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install eli5"],"metadata":{"id":"IFKvkoLKOARh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euGsoGKON4F6"},"outputs":[],"source":["import pandas as pd\n","import random\n","import os\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import make_regression\n","from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, VotingRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.multioutput import MultiOutputRegressor\n","from bayes_opt import BayesianOptimization\n","from sklearn.metrics import log_loss, mean_squared_error\n","\n","import xgboost as xgb\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor"]},{"cell_type":"markdown","source":["## data load"],"metadata":{"id":"MtaaGtw6Oh6V"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7UIdn-DTOALD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/contest/lg_auto_driving/data/train.csv')\n","\n","train_x = train_df.filter(regex='X') # Input : X Featrue\n","train_y = train_df.filter(regex='Y') # Output : Y Feature"],"metadata":{"id":"ARs3Gg5aOAN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## feature engineering"],"metadata":{"id":"zIg52OiyPJA9"}},{"cell_type":"code","source":["# rfecv의 결과로 column 5개 제거\n","train_x = train_x.drop(['X_02','X_04','X_23','X_47','X_48'], axis=1)"],"metadata":{"id":"sut3mrDEPYN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 6시그마 기준으로 outlier인 것과 아닌 것을 1,0으로 판별한 column 추가\n","for i in train_x.columns:\n","  ucl = train_x[i].mean()+3*train_x[i].std()\n","  lcl = train_x[i].mean()-3*train_x[i].std()\n","  for k,j in enumerate(train_x[i]):\n","    if j > ucl or j < lcl:\n","        train_x.loc[k, f'{i}_ct_outlier'] = 1 \n","    else:\n","        train_x.loc[k, f'{i}_ct_outlier'] = 0"],"metadata":{"id":"ydladWOIOl9_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## modeling1 - lgbm"],"metadata":{"id":"_yNP2qtyQped"}},{"cell_type":"code","source":["# 평가 성능지표\n","def lg_nrmse(gt, preds):\n","    # 각 Y Feature별 NRMSE 총합\n","    # Y_01 ~ Y_08 까지 20% 가중치 부여\n","    all_nrmse = []\n","    for idx in range(0,14): # ignore 'ID'\n","        rmse = mean_squared_error(gt.iloc[:,idx], preds[:,idx], squared=False)\n","        nrmse = rmse/np.mean(np.abs(gt.iloc[:,idx]))\n","        all_nrmse.append(nrmse)\n","    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])\n","    return score"],"metadata":{"id":"wu-T8DvhQB7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to optimize hyperparameter\n","lgbm_parameter_bounds = {\n","        'num_leaves': (16, 1024),        # num_leaves,       범위(16~1024)\n","        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n","        'n_estimators': (16, 1024),      # n_estimators,     범위(16~1024)\n","        'subsample': (0, 1),             # subsample,        범위(0~1)\n","        'colsample_bytree': (0, 1),      # colsample_bytree, 범위(0~1)\n","        'reg_alpha': (0, 10),            # reg_alpha,        범위(0~10)\n","        'reg_lambda': (0, 50),           # reg_lambda,       범위(0~50)\n","                      }\n","\n","\n","def lgbm_bo(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda):\n","    lgbm_params = {\n","                'num_leaves' : int(round(num_leaves)),\n","                'learning_rate' : learning_rate,\n","                'n_estimators' : int(round(n_estimators)),\n","                'subsample' : subsample,\n","                'colsample_bytree' : colsample_bytree,\n","                'reg_alpha' : reg_alpha,\n","                'reg_lambda' : reg_lambda     \n","              }\n","    \n","    lgbm = MultiOutputRegressor(LGBMRegressor(**lgbm_params))\n","    \n","    X_train, X_valid, y_train, y_valid = train_test_split(train_x,train_y,test_size = 0.2, )\n","    \n","    lgbm.fit(X_train,y_train)\n","\n","    score = lg_nrmse(y_valid, lgbm.predict(X_valid))\n","    return score"],"metadata":{"id":"a-prYXAcQBxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BO_lgbm = BayesianOptimization(f = lgbm_bo, pbounds = lgbm_parameter_bounds,random_state = 42)\n","BO_lgbm.maximize(init_points = 5, n_iter = 10)"],"metadata":{"id":"Y1Bx6LMXQzNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lgbm_model = MultiOutputRegressor(LGBMRegressor(\n","    \n","    colsample_bytree=0.5924 ,\n","    learning_rate=0.00474, n_estimators=628, \n","    num_leaves=187, reg_alpha=0.6505, \n","    reg_lambda=47.44, subsample=0.9656\n","\n",")).fit(train_x, train_y)"],"metadata":{"id":"AtZPUGfJQzD9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## postprocessing"],"metadata":{"id":"kswa7QW0Q9BK"}},{"cell_type":"code","source":["# 일부만을 뽑아서 중요도를 뽑기 위해서 train_test_split\n","x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"],"metadata":{"id":"nfACZy8cODHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# permutation importance를 통해 weight가 0인 column들은 삭제\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","\n","perm = PermutationImportance(lgbm_model, scoring = \"neg_mean_squared_error\", random_state = 42).fit(x_val, y_val)\n","eli5.show_weights(perm, top = 80, feature_names = x_val.columns.tolist())"],"metadata":{"id":"a8pzyoyiOC-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# outlier 새로 뽑은 것 추가, X_10 column 삭제\n","outlier_data = train_x.filter(like='outlier')\n","train_x = train_x.drop(outlier_data, axis=1)\n","train_x = train_x.drop('X_10', axis=1)\n","train_x = train_x.join(outlier_data[['X_32_ct_outlier','X_30_ct_outlier','X_55_ct_outlier','X_49_ct_outlier','X_29_ct_outlier','X_08_ct_outlier']])"],"metadata":{"id":"ZwDhpexjOC70"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## modeling2 - lgbm"],"metadata":{"id":"JnqvFviqq2_E"}},{"cell_type":"code","source":["lgbm_model = MultiOutputRegressor(LGBMRegressor(\n","    \n","    colsample_bytree=0.5924 ,\n","    learning_rate=0.00474, n_estimators=628, \n","    num_leaves=187, reg_alpha=0.6505, \n","    reg_lambda=47.44, subsample=0.9656\n","\n",")).fit(train_x, train_y)"],"metadata":{"id":"XD_6qszQq538"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"716HOKn0SlGZ"}},{"cell_type":"code","source":["test_x = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/contest/lg_auto_driving/data/test.csv').drop(columns=['ID'])\n","test_x = test_x.drop(['X_02','X_04','X_23','X_47','X_48'], axis=1)"],"metadata":{"id":"iBYXkM1bRmJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test dataset에도 train dataset에 한 것과 같은 전처리해주기\n","# 6시그마 기준으로 outlier인 것과 아닌 것을 1,0으로 판별한 column 추가\n","for i in test_x.columns:\n","  ucl = test_x[i].mean()+3*test_x[i].std()\n","  lcl = test_x[i].mean()-3*test_x[i].std()\n","  \n","  for k,j in enumerate(test_x[i]):\n","    if j > ucl or j < lcl:\n","        test_x.loc[k, f'{i}_ct_outlier'] = 1 \n","    else:\n","        test_x.loc[k, f'{i}_ct_outlier'] = 0"],"metadata":{"id":"XeWtm36fSUTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# outlier 새로 뽑은 것 추가, X_10 column 삭제\n","outlier_data = test_x.filter(like='outlier')\n","test_x = test_x.drop(outlier_data, axis=1)\n","test_x = test_x.drop('X_10', axis=1)\n","test_x = test_x.join(outlier_data[['X_32_ct_outlier','X_30_ct_outlier','X_55_ct_outlier','X_49_ct_outlier','X_29_ct_outlier','X_08_ct_outlier']])"],"metadata":{"id":"323IMAsbSUPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = lgbm_model.predict(test_x)"],"metadata":{"id":"Mioi4OxkSUGa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## submit"],"metadata":{"id":"MeYtPBchR1h_"}},{"cell_type":"code","source":["submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/contest/lg_auto_driving/data/sample_submission.csv')"],"metadata":{"id":"VpEChzKrR2ec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, col in enumerate(submit.columns):\n","    if col=='ID':\n","        continue\n","    submit[col] = preds[:,idx-1]\n","print('Done.')"],"metadata":{"id":"UYR7XSwiSBYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit.to_csv('/content/drive/MyDrive/Colab Notebooks/contest/lg_auto_driving/submit_0826_5.csv', index=False)"],"metadata":{"id":"ZxIl-h_UR-Su"},"execution_count":null,"outputs":[]}]}